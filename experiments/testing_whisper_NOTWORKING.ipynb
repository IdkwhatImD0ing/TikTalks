{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.intel.openvino import OVModelForSpeechSeq2Seq\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "model_id = \"openai/whisper-tiny\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = model_id.split(\"/\")[-1]\n",
    "\n",
    "if not Path(model_dir).exists():\n",
    "    !optimum-cli export openvino -m {model_id} {model_dir} --weight-format fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[ERROR] 08:06:08.786 [NPUBackends] Cannot find backend for inference. Make sure the device is available.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d68417e6f5458283730d7cf33729cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=2, options=('CPU', 'GPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    ")\n",
    "open(\"notebook_utils.py\", \"w\").write(r.text)\n",
    "\n",
    "from notebook_utils import device_widget\n",
    "\n",
    "device = device_widget()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the encoder to AUTO ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[ERROR] 08:06:53.631 [NPUBackends] Cannot find backend for inference. Make sure the device is available.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the decoder to AUTO ...\n",
      "Compiling the decoder to AUTO ...\n"
     ]
    }
   ],
   "source": [
    "from optimum.intel.openvino import OVModelForSpeechSeq2Seq\n",
    "from transformers import AutoProcessor, pipeline\n",
    "\n",
    "ov_model = OVModelForSpeechSeq2Seq.from_pretrained(model_dir, device=device.value)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_dir)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=ov_model,\n",
    "    chunk_length_s=30,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c8ccca3a3741aab3e5907aa17c8eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='https://youtu.be/kgL5LBM-hFI', description='Video:', placeholder='Type link for video')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "VIDEO_LINK = \"https://youtu.be/kgL5LBM-hFI\"\n",
    "link = widgets.Text(\n",
    "    value=VIDEO_LINK,\n",
    "    placeholder=\"Type link for video\",\n",
    "    description=\"Video:\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video https://youtu.be/kgL5LBM-hFI started\n",
      "[youtube] Extracting URL: https://youtu.be/kgL5LBM-hFI\n",
      "[youtube] kgL5LBM-hFI: Downloading webpage\n",
      "[youtube] kgL5LBM-hFI: Downloading ios player API JSON\n",
      "[youtube] kgL5LBM-hFI: Downloading web creator player API JSON\n",
      "[youtube] kgL5LBM-hFI: Downloading player b0557ce3\n",
      "[youtube] kgL5LBM-hFI: Downloading m3u8 information\n",
      "[info] kgL5LBM-hFI: Downloading 1 format(s): 18\n",
      "[download] Destination: downloaded_video.mp4\n",
      "[download] 100% of    1.20MiB in 00:00:01 at 722.63KiB/s \n",
      "Video saved to downloaded_video.mp4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yt_dlp\n",
    "\n",
    "print(f\"Downloading video {link.value} started\")\n",
    "\n",
    "output_file = Path(\"downloaded_video.mp4\")\n",
    "ydl_ops = {\"format\": \"best[ext=mp4]\", \"outtmpl\": output_file.as_posix()}\n",
    "with yt_dlp.YoutubeDL(ydl_ops) as ydl:\n",
    "    ydl.download(link.value)\n",
    "\n",
    "print(f\"Video saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93893db0c8dd42859395a44f97e18b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Select task:', index=1, options=('transcribe', 'translate'), value='translate')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = widgets.Select(\n",
    "    options=[\"transcribe\", \"translate\"],\n",
    "    value=\"translate\",\n",
    "    description=\"Select task:\",\n",
    "    disabled=False,\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from transformers.pipelines.audio_utils import ffmpeg_read\n",
    "\n",
    "\n",
    "def get_audio(video_file):\n",
    "    \"\"\"\n",
    "    Extract audio signal from a given video file, then convert it to float,\n",
    "    then mono-channel format and resample it to the expected sample rate\n",
    "\n",
    "    Parameters:\n",
    "        video_file: path to input video file\n",
    "    Returns:\n",
    "      resampled_audio: mono-channel float audio signal with 16000 Hz sample rate\n",
    "                       extracted from video\n",
    "      duration: duration of video fragment in seconds\n",
    "    \"\"\"\n",
    "    input_video = VideoFileClip(str(video_file))\n",
    "    duration = input_video.duration\n",
    "    audio_file = video_file.stem + \".wav\"\n",
    "    input_video.audio.write_audiofile(audio_file, verbose=False, logger=None)\n",
    "    with open(audio_file, \"rb\") as f:\n",
    "        inputs = f.read()\n",
    "    audio = ffmpeg_read(inputs, pipe.feature_extractor.sampling_rate)\n",
    "    return {\n",
    "        \"raw\": audio,\n",
    "        \"sampling_rate\": pipe.feature_extractor.sampling_rate,\n",
    "    }, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n"
     ]
    }
   ],
   "source": [
    "inputs, duration = get_audio(output_file)\n",
    "\n",
    "transcription = pipe(inputs, generate_kwargs={\"task\": task.value}, return_timestamps=True)[\"chunks\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiktalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
