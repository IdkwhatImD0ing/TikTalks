{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 08:56:14,035 - INFO - Using device: cpu\n",
      "2024-09-27 08:56:14,036 - INFO - Loading model 'openai/whisper-tiny.en' for task 'transcribe'.\n",
      "2024-09-27 08:56:14,815 - INFO - Loading audio file: output/audio.wav\n",
      "2024-09-27 08:56:14,912 - INFO - Running transcription...\n",
      "/home/intelaipc/intel/oneapi/intelpython/envs/tiktalk/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "2024-09-27 08:56:17,723 - INFO - Transcription completed.\n",
      "Formatting transcription: 100%|██████████| 17/17 [00:00<00:00, 165821.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a world where humanity has finally reached the stars and we're not just talking | start: 0.0 | end: 5.28\n",
      "about any old spacecraft, but the most advanced cutting edge and sustainable vessels that are | start: 5.28 | end: 11.64\n",
      "changing the game. | start: 11.64 | end: 13.68\n",
      "Space ships are not just a luxury, they are a necessity. | start: 13.68 | end: 17.04\n",
      "They are the key to unlocking new frontiers, new discoveries and new possibilities for humanity. | start: 17.04 | end: 23.36\n",
      "But did you know that the first spaceship | start: 23.36 | end: 25.52\n",
      "was actually a hot air balloon? Yes, you heard that right. In 1783, French inventor | start: 25.52 | end: 32.74\n",
      "Montgolfier created the first successful hot air balloon which carried a group of 20 people | start: 32.74 | end: 38.64\n",
      "to the skies. It was a groundbreaking achievement that paved the way for the development of modern space travel. | start: 38.64 | end: 45.92\n",
      "Fast forward to today, and we have reusable rockets, advanced propulsion systems, | start: 45.92 | end: 51.44\n",
      "and even private space companies like SpaceX and Blue Origin pushing the boundaries of what's possible. | start: 51.44 | end: 58.24\n",
      "But what's even more exciting is that we're not just talking about the technology, | start: 58.24 | end: 63.04\n",
      "we're talking about the people, the communities, and the cultures that are being shaped by space exploration. | start: 63.04 | end: 70.04\n",
      "From the astronauts who are pushing the limits of human endurance to the scientists who | start: 70.04 | end: 74.84\n",
      "are unlocking the secrets of the universe, space travel is not just a dream, it's a reality | start: 74.84 | end: 80.6\n",
      "that's changing our world. | start: 80.6 | end: 82.76\n",
      "So let's get ready to blast off into the unknown and explore the infinite possibilities | start: 82.76 | end: 88.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def transcribe_wav(wav_path, model_name=\"openai/whisper-tiny.en\", device=None, task='transcribe', batch_size=8):\n",
    "    \"\"\"\n",
    "    Transcribe a WAV audio file using Whisper with Hugging Face pipeline and return a formatted string.\n",
    "    \n",
    "    Parameters:\n",
    "        wav_path (str or Path): Path to the input WAV audio file.\n",
    "        model_name (str): Hugging Face model name.\n",
    "        device (str or int, optional): Device to run the model on ('cpu', 'cuda:0', etc.). Defaults to automatic selection.\n",
    "        task (str): Task type ('transcribe' or 'translate').\n",
    "        batch_size (int): Batch size for processing.\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted transcription string with timestamps.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine device\n",
    "        if device is None:\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        logging.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Initialize the pipeline\n",
    "        logging.info(f\"Loading model '{model_name}' for task '{task}'.\")\n",
    "        pipe = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=model_name,\n",
    "            chunk_length_s=30,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        # Load the WAV file\n",
    "        wav_path = Path(wav_path)\n",
    "        if not wav_path.exists():\n",
    "            raise FileNotFoundError(f\"Audio file not found: {wav_path}\")\n",
    "        \n",
    "        logging.info(f\"Loading audio file: {wav_path}\")\n",
    "        audio_input, sr = sf.read(wav_path)\n",
    "        inputs = {\n",
    "            \"raw\": audio_input,\n",
    "            \"sampling_rate\": sr,\n",
    "        }\n",
    "\n",
    "        # Perform transcription with timestamps\n",
    "        logging.info(\"Running transcription...\")\n",
    "        transcription_chunks = pipe(\n",
    "            inputs,\n",
    "            batch_size=batch_size,\n",
    "            return_timestamps=True\n",
    "        ).get(\"chunks\", [])\n",
    "\n",
    "        logging.info(\"Transcription completed.\")\n",
    "\n",
    "        # Format transcription into desired string\n",
    "        formatted_transcription = format_transcription(transcription_chunks)\n",
    "\n",
    "        return formatted_transcription\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"Error: {fnf_error}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def format_transcription(transcription_chunks):\n",
    "    \"\"\"\n",
    "    Format transcription chunks into the desired string format.\n",
    "\n",
    "    Each line contains:\n",
    "    Transcribed text | start: X | end: Y\n",
    "\n",
    "    Parameters:\n",
    "        transcription_chunks (list): List of transcription chunks with timestamps.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted transcription string.\n",
    "    \"\"\"\n",
    "    formatted_output = \"\"\n",
    "    for segment in tqdm(transcription_chunks, desc=\"Formatting transcription\"):\n",
    "        text = segment.get(\"text\", \"\").strip()\n",
    "        start, end = segment.get(\"timestamp\", (0.0, 0.0))\n",
    "        # Round the timestamps to two decimal places\n",
    "        start_rounded = round(start, 2)\n",
    "        end_rounded = round(end, 2) if end else round(start + 5.0, 2)  # Default to start + 5.0 if end is None\n",
    "        formatted_output += f\"{text} | start: {start_rounded} | end: {end_rounded}\\n\"\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "transcription_text = transcribe_wav(\"output/audio.wav\")\n",
    "print(transcription_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiktalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
