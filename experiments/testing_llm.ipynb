{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One: Generating a script for the video based on a sentence\n",
    "\n",
    "First: run this command to get the model: \n",
    "\n",
    "Non Instruct:\n",
    "```\n",
    "optimum-cli export openvino --model meta-llama/Llama-3.2-1B --task text-generation-with-past ./Llama-3.2-1B_openvino\n",
    "```\n",
    "\n",
    "Instruct:\n",
    "```\n",
    "optimum-cli export openvino --model meta-llama/Llama-3.2-1B-Instruct --task text-generation-with-past ./Llama-3.2-1B-Instruct_openvino\n",
    "```\n",
    "\n",
    "With Quanitization: \n",
    "\n",
    "Non Instruct:\n",
    "```\n",
    "optimum-cli export openvino --model meta-llama/Llama-3.2-1B --task text-generation-with-past --weight-format int8 ./Llama-3.2-1B_openvino_INT8\n",
    "```\n",
    "\n",
    "Instruct:\n",
    "```\n",
    "optimum-cli export openvino --model meta-llama/Llama-3.2-1B-Instruct --task text-generation-with-past --weight-format int8 ./Llama-3.2-1B-Instruct_openvino_INT8\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intelaipc/intel/oneapi/intelpython/envs/tiktalk/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/intelaipc/intel/oneapi/intelpython/envs/tiktalk/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "import openvino.runtime as ov\n",
    "\n",
    "# Path to the converted model\n",
    "model_dir = \"./Llama-3.2-1B-instruct_openvino_INT8\"\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "\n",
    "# Select device (CPU or GPU)\n",
    "device = \"CPU\"  # Change to \"GPU\" if available and desired\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = OVModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device=device,\n",
    "    config=AutoConfig.from_pretrained(model_dir, trust_remote_code=True),\n",
    "    trust_remote_code=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_chat_response(prompt: str,\n",
    "                          max_new_tokens: int = 256,\n",
    "                          temperature: float = 1.0,\n",
    "                          top_p: float = 0.9,\n",
    "                          top_k: int = 50,\n",
    "                          repetition_penalty: float = 1.2) -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat response using the Llama-3.2-1B-Instruct model.\n",
    "\n",
    "    Parameters:\n",
    "        prompt (str): The input string for the chatbot.\n",
    "        max_new_tokens (int): Maximum number of tokens to generate.\n",
    "        temperature (float): Sampling temperature.\n",
    "        top_p (float): Nucleus sampling parameter.\n",
    "        top_k (int): Top-K sampling parameter.\n",
    "        repetition_penalty (float): Repetition penalty.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "    \"\"\"\n",
    "    # Tokenize the input prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    # Decode the output tokens\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Optionally, remove the prompt from the response\n",
    "    if response.startswith(prompt):\n",
    "        response = response[len(prompt):].strip()\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\n\\n\n",
    "Your task is to create a 30 second engaging and educational tiktok script based on the following sentence:\n",
    "\n",
    "{input_sentence}\n",
    "\n",
    "Expand on this sentence to create an interesting and educational script that most people might not know about.\n",
    "The tiktok should incorporate an engaging story or example related to the sentence.\n",
    "Do not include any emojis or hashtags in the script.\n",
    "The script should be only spoken text, no extra text like [Cut] or [Music].\n",
    "The script should sound passionate, excited, and happy.\n",
    "\n",
    "Script:\n",
    "\"\"\"\n",
    "\n",
    "sentence = \"Spaceships are the future of human travel.\"\n",
    "\n",
    "user_input = prompt.format(input_sentence=sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Imagine living on Mars one day - it's already happening. In fact, NASA has been sending astronauts all over space for decades. But what you may not know is how they're doing exactly as planned.\"\n",
      "\n",
      "\"But did you know they have to wait years between launches? Because each launch costs millions dollars per seat! That means every dollar going towards building new spaceships and spacecraft is contributing towards making humanity multiplanetary.\" \n",
      "\n",
      "\"You see, our planet Earth was facing extinction from asteroids and other dangers, but now we can't let another disaster happen while trying to explore the cosmos with just two small planets nearby: earth and mars.\" \"It could get ugly very fast if there aren't enough resources available elsewhere so humans have made agreements such as the Artemis Program which would help us acquire more resources before being able to establish itself officially\"\n"
     ]
    }
   ],
   "source": [
    "response = generate_chat_response(user_input, max_new_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Imagine a world where humanity has finally reached the stars, and we're not just talking about any old spacecraft, but the most advanced, cutting-edge, and sustainable vessels that are changing the game. Spaceships are not just a luxury, they're a necessity. They're the key to unlocking new frontiers, new discoveries, and new possibilities for humanity. But did you know that the first spaceship was actually a hot air balloon? Yes, you heard that right! In 1783, French inventor Montgolfier created the first successful hot air balloon, which carried a group of 20 people to the skies. It was a groundbreaking achievement that paved the way for the development of modern space travel. Fast forward to today, and we have reusable rockets, advanced propulsion systems, and even private space companies like SpaceX and Blue Origin pushing the boundaries of what's possible. But what's even more exciting is that we're not just talking about the technology, we're talking about the people, the communities, and the cultures that are being shaped by space exploration. From the astronauts who are pushing the limits of human endurance to the scientists who are unlocking the secrets of the universe, space travel is not just a dream, it's a reality that's changing our world. So let's get ready to blast off into the unknown, and explore the infinite possibilities that await us in the cosmos!\"\n"
     ]
    }
   ],
   "source": [
    "import openvino_genai as ov_genai\n",
    "pipe = ov_genai.LLMPipeline(model_dir, \"CPU\")\n",
    "print(pipe.generate(user_input, max_new_tokens=1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiktalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
